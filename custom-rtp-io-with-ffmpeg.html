<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Custom RTP I/O with FFmpeg | Kevin's Blog</title>
    <link rel="stylesheet" href="https://unpkg.com/normalize.css" />
    <link rel="stylesheet" href="https://unpkg.com/concrete.css" />
    <link rel="stylesheet" href="/style.css" />

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@muxfdz" />

    <meta name="viewport" content="width=device-width,initial-scale=1" />
  </head>
  <body>
    <a href="/">Back to the blog</a>
    <h1>Custom RTP I/O with FFmpeg</h1>
    <em>February 28th, 2022</em>
    <p>
      At <a href="https://muxable.com">Muxable</a>, we use
      <a href="https://www.ffmpeg.org/">FFmpeg</a> to transcode WebRTC streams
      with our <a href="https://github.com/muxable/transcoder">transcoder</a>.
      The transcoder receives an RTP stream over cell networks with
      <a href="https://pion.ly/">Pion</a> and also uses Pion to write the
      transcoded RTP stream to the client. However, piping an RTP stream in
      memory to FFmpeg is a bit undocumented. I
      <a
        href="http://ffmpeg.org/pipermail/ffmpeg-devel/2022-February/292665.html"
        >asked</a
      >
      <a
        href="https://stackoverflow.com/questions/71000853/demuxing-and-decoding-raw-rtp-with-libavformat"
        >around</a
      >
      and haven't been able to find a documented answer leading me to think that
      it wasn't actually possible with the current FFmpeg APIs. Last week I got
      an email from
      <a href="https://github.com/YCChiang">YCChiang</a> suggesting that it
      might be possible! In the interest of documenting this path better, this
      post describes how it's done.
    </p>
    <h2>SDP-triggered RTP flows</h2>
    <p>
      The first step is to create an SDP. In <code>libavformat</code>, an SDP
      input triggers an RTP source. You can create a minimal SDP that looks
      like:
    </p>
    <pre>
v=0
o=- 0 0 IN IP4 127.0.0.1
s=No Name
c=IN IP4 127.0.0.1
t=0 0
a=tool:libavformat 58.29.100
m=video 5000 RTP/AVP 96
a=rtpmap:96 H264/90000
a=fmtp:96 level-asymmetry-allowed=1;packetization-mode=1;profile-level-id=42001f</pre
    >
    <p>
      Inputting this file with ffplay
      <code>ffplay -protocol_whitelist file,rtp,udp -i video.sdp</code> will
      listen on port 5000 for RTP packets.
    </p>
    <p>
      Therefore, the first step is to generate a temporary SDP file. Our code to
      do that can be found
      <a
        href="https://github.com/muxable/transcoder/blob/main/internal/av/temp_sdp.go"
        >here</a
      >. Since we will be piping the RTP packets over memory, the choice of port
      and IPs doesn't matter. However, the payload type must match.
    </p>
    <h2>Setting the custom_io flag</h2>
    <p>
      The SDP file that we generate is passed to
      <code>avformat_open_input()</code> and we follow the typical flow to
      create an <code>AVIOContext</code>. Crucially, we must also set the flag
      <code>RTSP_FLAG_CUSTOM_IO</code> to indicate that the RTSP receiver will
      also use the custom IO provided by <code>AVIOContext</code>.
    </p>
    <pre>
    AVInputFormat *file_iformat = av_find_input_format("sdp");
    AVFormatContext *ic = avformat_alloc_context();
    AVDictionary *format_opts = NULL;
    av_dict_set(&format_opts, "sdp_flags", "custom_io", 0);
    avformat_open_input(&ic, "video.sdp", file_iformat, &format_opts);
    uint8_t *readbuf = (uint8_t *)av_malloc(4096);
    AVIOContext * avio_in = avio_alloc_context(readbuf, 4096, 1, video_queue, &read_packet, &write_packet, NULL);
    ic->pb = avio_in;</pre
    >
    <p>
      In the above example, we configure <code>libavformat</code> to use a
      custom i/o stream and then also set the
      <code>RTSP_FLAG_CUSTOM_IO</code> flag to indicate that we should use the
      custom i/o. It's unclear to me why this is not the default, but the
      <code>av_dict_set(&format_opts, "sdp_flags", "custom_io", 0);</code> line
      is crucial.
    </p>
    <p>
      Interestingly, there is also a bug in the FFmpeg code right now so a
      <code>write_packet</code> function <strong>must</strong> be passed in. See
      <a href="https://trac.ffmpeg.org/ticket/9670">this ticket</a> for more
      details.
    </p>
  </body>
</html>
